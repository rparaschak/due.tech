# Future of AI Coding Agents: Bubble or Future?

Subtitle: AI makes elite teams better and broken teams worse. The gap is widening. This isn't hype - it's data.

Some people are speculating about the AI bubble bursting. But what does that even mean? The models will get dumber? Slower? Stop existing? I think they mean the hype will fade, the funding will dry up, the growth will slow down. They're missing the point.

## The Problem Isn't Model Performance

The problem isn't whether Claude 5 will be better than Claude 4. It will be. The problem is that most companies aren't even using what's available right now. With today's models, you can automate work that was impossible five years ago. Or possible only with massive teams and budgets.

<example>
Here's a real example from my client. They hired two people to manually scrape websites, collect data, and enter it into their system through web forms. The data was unstructured, so traditional automation didn't work well enough. Their throughput? 6-8 items per hour.

We built an AI agent that processes 50 items per hour. Could do more, but validation became the bottleneck. Now those two people just validate instead of doing data entry. Throughput jumped to 40 items per hour.

That's a 5x boost. For pennies in compute costs.
</example>

The tech was already there. They just weren't using it.

## LLMs Aren't Going Anywhere

Let's play out the worst-case scenarios. Say LLM development stops tomorrow. No new models from now on. Does that mean we shouldn't adopt existing models? Wrong. We don't even use existing models to their fullest potential. The gap isn't between what models can do and what we need – it's between what models can do and what we're actually doing with them.

What if LLMs become too expensive? Well, today you can download an open-source model and deploy it either on your laptop or in your data center. The LLM revolution created a boom, and now we have models you can own outright. You're not locked into any vendor. You're not dependent on API pricing. You don't need to wait for GPT-5 or whatever comes next. The tools exist today.

Some people worry that what we adopt today won't be relevant because new models are coming and everything will change. I don't think so. The fundamentals that worked two years ago remain the same. Tools just became more powerful and smarter. What you learn now about prompting, about breaking down tasks, about validation and error handling – that carries forward. We're just extending those fundamentals to make work with AI more effective.

Every new model generation brings more thinking capability, better instruction following, faster inference, lower costs. Security is improving. You can use big cloud providers or keep everything in your isolated environment. LLMs are here to stay. You have no choice but to learn how to live with them.

## Many Companies Are Getting This Wrong

I see two patterns in the market. Companies refusing to adopt – they tried AI once, it didn't work, so they decided it's all hype. And companies adopting badly – they bought the shiniest tools, gave everyone access, and wondered why nothing improved. Both approaches lose.

<example>
In my company, we use AI heavily for software development. One thing that works well is automated testing. We have an AI agent that generates tests for our API and MCP endpoints. It covers the happy path cases. We spend minutes reviewing them instead of hours writing them. This is just one of many workflows where AI makes a real difference for us.
</example>

But we didn't start there. We had to do groundwork first.

## What DORA 2025 Actually Tells Us

The DORA Report 2025 reveals something uncomfortable. While AI boosts throughput, software delivery stability continues to decline. The gap between high-performing and struggling teams isn't just staying the same—AI is actively widening it.

Here's the key insight: "AI magnifies the strengths of high-performing organizations and the dysfunctions of struggling ones."

Read that again. AI doesn't fix broken teams. It makes them worse. If your processes are chaotic, AI adds chaos faster. If your communication is bad, AI helps you miscommunicate at scale. Better models will only widen this gap further.

## You Have Three Options

**Give AI to a dysfunctional team.** Watch your problems multiply. Faster code reviews won't help if you're reviewing the wrong things. Faster code generation won't matter if you're building the wrong features.

**Ignore AI entirely.** Lose competitive advantage to companies that figure it out. While you're debating whether AI is hype, your competitors are shipping faster, learning faster, and pulling ahead.

**Adopt it strategically.** Do the groundwork first. Start small. Prove value. Scale what works. This is the only path that actually leads somewhere good.

<example>
In my company, we have significant productivity gains. But they didn't happen because we bought the best tools. They happened because we applied them systematically, step by step, through trial and error. At this point, we can't imagine our workflow without AI assistance.
</example>

## The Real Question

The bubble talk misses what matters. It's not whether AI will keep improving. It will. The question is whether you'll adopt it before your competitors do. Whether you'll do the work to make your team ready for it. Whether you'll start now or wait until you're too far behind to catch up.

More powerful models are coming. Specialized models are coming. Cheaper models are coming. But if you're not adopting what exists today, those future models won't save you either. The advantage goes to companies that move now. As an employer and as an employee, you need to figure this out.

Start small. Start today. Start with one workflow that matters. Because the models aren't going anywhere. And neither is the competitive pressure they create.
